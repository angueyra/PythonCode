{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import h5py\n",
    "\n",
    "class espion_file:\n",
    "    \"\"\"Loader for erg ESPION CSV files into Python\"\"\"\n",
    "    def __init__(self, filepath, filename, species, genotype):\n",
    "        self.basedir = \"/Users/angueyraaristjm/Documents/LiData/invivoERG/\"\n",
    "        self.filepath = filepath\n",
    "        self.filename = filename\n",
    "        self.savepath = self.basedir + self.filepath + \"/\"\n",
    "        self.fullpath = self.savepath + self.filename + \".csv\"\n",
    "        self.species = species\n",
    "        self.genotype = genotype\n",
    "        self.metadata = self.pull_metadata()\n",
    "        self.datatable = self.pull_datatable()\n",
    "        self.data = self.pull_data()\n",
    "        self.HDF5remap()\n",
    "    \n",
    "    def pull_metadata(self):\n",
    "        # pull and parse metadata information\n",
    "        csvparams = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1], nrows=10, low_memory=False)\n",
    "        csvparams = csvparams.dropna()\n",
    "        metadata = dict()\n",
    "        intfields = [\"Steps\", \"Channels\"]\n",
    "        datefields = [\"DOB\", \"Date performed\"]\n",
    "        for i in range(1, 10):\n",
    "            if csvparams.Parameter[i] in intfields:\n",
    "                metadata[csvparams.Parameter[i]] = int(csvparams.Value[i])\n",
    "            elif csvparams.Parameter[i] in datefields:\n",
    "                metadata[csvparams.Parameter[i]] = pandas.to_datetime(csvparams.Value[i])\n",
    "            elif csvparams.Parameter[i] == \"Family Name\":\n",
    "                metadata[\"ID\"] = csvparams.Value[i]\n",
    "            else: \n",
    "                metadata[csvparams.Parameter[i]] = csvparams.Value[i]\n",
    "        metadata['Species'] = self.species\n",
    "        metadata['genotype'] = self.genotype\n",
    "        return metadata\n",
    "                \n",
    "    def pull_datatable(self):\n",
    "        # pull datatable to parse data\n",
    "        fullcsv = pandas.read_csv(self.fullpath, header=0, low_memory=False)\n",
    "        if \"Data Table\" in fullcsv:\n",
    "            #print(\"Data Table is Right\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[3, 4, 5, 8], low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        elif fullcsv.ix[12, 0] == \"Data Table\":\n",
    "            #print(\"Data Table is Below\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1, 2, 5], skiprows=13, low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        elif fullcsv.ix[13, 0] == \"Data Table\":\n",
    "            #print(\"Data Table is Below\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1, 2, 5], skiprows=14, low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        else:\n",
    "            print(\"Did not find datatable\")\n",
    "        return datatable\n",
    "    \n",
    "    def pull_data(self):\n",
    "        # parse data based on data table\n",
    "        fullcsv = pandas.read_csv(self.fullpath, header=0, low_memory=False)\n",
    "        data = dict()\n",
    "        for step in range(self.metadata['Steps']):\n",
    "            stepname = \"Step\" + str(step+1).zfill(2)\n",
    "            # print(stepname)\n",
    "            ch1start = self.datatable.Column[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==1)]\n",
    "            ch2start = self.datatable.Column[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==2)]\n",
    "            ntrials = self.datatable.Trials[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==1)]\n",
    "            if len(ch1start)==1:\n",
    "                #normally each step runs only once but if it's repeated, ESPION doubles the entries\n",
    "                ch1start = int(ch1start)\n",
    "                ch2start = int(ch2start-1)\n",
    "                ntrials = int(ntrials)\n",
    "                data[stepname] = self.espion_step(ch1start=ch1start, ch2start=ch2start, ntrials=ntrials, csvtable=fullcsv)\n",
    "            elif len(ch1start.unique())==1:\n",
    "                #found duplicates but all have the same column start\n",
    "                ch1start = int(ch1start.unique())\n",
    "                ch2start = int(ch2start.unique()-1)\n",
    "                ntrials = int(ntrials.sum())\n",
    "                data[stepname] = self.espion_step(ch1start=ch1start, ch2start=ch2start, ntrials=ntrials, csvtable=fullcsv)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def espion_step(ch1start, ch2start, ntrials, csvtable):\n",
    "        \"\"\"Loader for a single erg ESPION step\"\"\"\n",
    "        colstart = ch1start-1\n",
    "        colend = colstart+1+(ntrials*2)\n",
    "        currcsv = csvtable.ix[0:, colstart:colend].copy(deep=0)\n",
    "        currcsv = currcsv.dropna().reset_index(drop=True)\n",
    "        currcsv = currcsv.drop(0).reset_index(drop=True)\n",
    "        colnames = []\n",
    "        ch1cnt = 0\n",
    "        ch2cnt = 0\n",
    "        for i in range(0, len(currcsv.columns)):\n",
    "            currcsv.ix[0:, i] = pandas.to_numeric(currcsv.ix[0:, i])\n",
    "            if i == 0:\n",
    "                colnames.append('t')\n",
    "            elif 1 <= i < 1+ntrials:\n",
    "                ch1cnt += 1\n",
    "                colnames.append('L' + str(ch1cnt).zfill(2))\n",
    "            elif 1+ntrials <= i < 1+(ntrials*2):\n",
    "                ch2cnt += 1\n",
    "                colnames.append('R' + str(ch2cnt).zfill(2))\n",
    "        currcsv.columns = colnames\n",
    "        currcsv = currcsv.divide(1000)\n",
    "        csvoutput = currcsv.copy()\n",
    "        return csvoutput\n",
    "\n",
    "    def HDF5remap(self):\n",
    "        dt = h5py.special_dtype(vlen=bytes)\n",
    "        intfields = [\"Steps\", \"Channels\"]\n",
    "        \n",
    "        h5name = self.savepath + self.filename + \".h5\"\n",
    "        print('Saving h5 file...')\n",
    "        with h5py.File(h5name, 'w') as hfile:\n",
    "#             print('\\tFrom datatable:')\n",
    "            for col in self.datatable.columns:\n",
    "                hfile.create_dataset(col.replace(' ','_'), data=self.datatable.get(col))\n",
    "#                 print('\\t\\t'+ col)\n",
    "#             print('\\tFrom metadata:')\n",
    "            for key in self.metadata:\n",
    "                if key in intfields:\n",
    "                    hfile.attrs.create(key.replace(' ','_'), data=self.metadata[key])\n",
    "                else:\n",
    "                    hfile.attrs.create(key.replace(' ','_'), data=str(self.metadata[key]), dtype=dt)\n",
    "#                 print('\\t\\t' + key)\n",
    "            # print('\\tFrom data:')\n",
    "            for step in self.data:\n",
    "                group = hfile.create_group(step)\n",
    "                group.create_dataset('t', data=self.data[step].filter(regex = 't'))\n",
    "                group.create_dataset('L', data=self.data[step].filter(regex = 'L'))\n",
    "                group.create_dataset('R', data=self.data[step].filter(regex = 'R'))\n",
    "                # print('\\t\\t' + step)\n",
    "        print('Saved to: ' + h5name + '\\n')\n",
    "        \n",
    "# if __name__ == \"__main__\":\n",
    "#     a = espion_file(\"20160928/20160928_wl05_2_eml1het\", \"20160928_wl05_2_01_iSscotdark\", \"Mouse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20170309/20170309_wl05_107_wt/01_iSeriesScotopicStitch.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map a single espion csv exported file to hdf5\n",
    "a = espion_file(\"20170309/20170309_wl05_107_wt\", \"01_iSeriesScotopicStitch\", \"Mouse\", \"wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genotypes\n",
    "# wt\n",
    "# eml1+/-\n",
    "# eml1-/-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_01_IsXe.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_02_sSGreen.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_03_sine.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_04_prebleach.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_05_bleach.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_06_postbleach.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20160815/20160815_Sq922/20160815_Sq922_07_sinepost.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map all espion csv exported files on a single folder to hdf5\n",
    "import os\n",
    "\n",
    "path={};\n",
    "path['datafolder']='20160815/20160815_Sq922'\n",
    "path['species']='Squirrel'\n",
    "path['root'] = '/Users/angueyraaristjm/Documents/LiData/invivoERG/'\n",
    "path['fullpath']=path['root']+path['datafolder']+'/'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path['fullpath'], topdown=True):\n",
    "    dirs.clear() #with topdown true, this will prevent walk from going into subs\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            fName=file[:-4]\n",
    "            if (fName + \".h5\") in files:\n",
    "                print(fName + ' is already mapped')\n",
    "            else:\n",
    "                erg = espion_file(path['datafolder'], fName, path['species'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160815_Sq922_01_IsXe\n",
      "20160815_Sq922_02_sSGreen\n",
      "20160815_Sq922_03_sine\n",
      "20160815_Sq922_04_prebleach\n",
      "20160815_Sq922_05_bleach\n",
      "20160815_Sq922_06_postbleach\n",
      "20160815_Sq922_07_sinepost\n"
     ]
    }
   ],
   "source": [
    "# spit out list of csv files\n",
    "import os\n",
    "\n",
    "path={};\n",
    "path['datafolder']='20160815/20160815_Sq922'\n",
    "path['species']='Squirrel'\n",
    "path['root'] = '/Users/angueyraaristjm/Documents/LiData/invivoERG/'\n",
    "path['fullpath']=path['root']+path['datafolder']+'/'\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(path['fullpath'], topdown=True):\n",
    "    dirs.clear() #with topdown true, this will prevent walk from going into subs\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            fName=file[:-4]\n",
    "            print(fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
