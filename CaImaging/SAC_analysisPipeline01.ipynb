{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to get some sort of automated analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/angueyraaristjm/anaconda3/lib/python3.7/site-packages (4.6.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install suite2p\n",
    "# !pip install scanimage-tiff-reader\n",
    "# !pip install -U scikit-image\n",
    "# !pip install tiffile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/ChAT_gCaMP6s_example2\n"
     ]
    }
   ],
   "source": [
    "cd '/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/ChAT_gCaMP6s_example2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/ChAT_gCaMP6s_example2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tifroot = !pwd\n",
    "tifroot = tifroot[0]\n",
    "tifroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ScanImageTiffReader import ScanImageTiffReader as sitr\n",
    "from tifffile import TiffFile, imwrite, xml2dict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def scan_metadata(tif_file):\n",
    "    from tiffile import xml2dict\n",
    "    xml_metadata = xml2dict(tif.description(0))\n",
    "    metadata = {\n",
    "        'Lt' : xml_metadata['OME']['Image']['Pixels']['SizeT'],\n",
    "        'Lx' : xml_metadata['OME']['Image']['Pixels']['SizeX'],\n",
    "        'Ly' : xml_metadata['OME']['Image']['Pixels']['SizeY'],\n",
    "        'nChannels' :  xml_metadata['OME']['Image']['Pixels']['SizeC'],\n",
    "        'realX' : np.multiply(xml_metadata['OME']['StructuredAnnotations']['XMLAnnotation'][3]['Value']['ImagePhysicalDimensions']['PhysicalSizeX'],1e6), # in um\n",
    "        'realY' : np.multiply(xml_metadata['OME']['StructuredAnnotations']['XMLAnnotation'][3]['Value']['ImagePhysicalDimensions']['PhysicalSizeY'],1e6), # in um\n",
    "        'realT' : xml_metadata['OME']['StructuredAnnotations']['XMLAnnotation'][3]['Value']['ImagePhysicalDimensions']['PhysicalSizeT'], # in s\n",
    "        'samplingRate' : np.divide(Lt,realT),\n",
    "\n",
    "        'fname_original' : fname,\n",
    "        'fname' : fname + '_rg',\n",
    "    }\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sould define a tif object:\n",
    "* load tif only once\n",
    "* im just call tif.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lt': 840,\n",
       " 'Lx': 256,\n",
       " 'Ly': 128,\n",
       " 'nChannels': 1,\n",
       " 'realX': 76.25,\n",
       " 'realY': 38.125,\n",
       " 'realT': 137.6256,\n",
       " 'samplingRate': 6.103515625,\n",
       " 'fname_original': '20190520_L03_04Bars_Original',\n",
       " 'fname': '20190520_L03_04Bars_Original_rg'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '20190520_L03_04Bars_Original';\n",
    "tif = sitr(fname + '.tif')\n",
    "im = tif.data()\n",
    "xml_metadata = xml2dict(tif.description(0))\n",
    "metadata = scan_metadata(tif)\n",
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190520_L03_04Bars_Original_rg'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.830400000000001"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(tifroot, fname + '.tif')\n",
    "# io.imsave(os.path.join(tifroot, fname), dwrite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notes:\n",
    "\n",
    "> Would be great to extract things from tiff files beforehand including:\n",
    "\n",
    "> fs (sampling rate)\n",
    "\n",
    "> length (to inform nimg_init)\n",
    "\n",
    "> number of channels \n",
    "\n",
    "SciScan Tiff Reader does not support compressed data. Make sure to save as uncompressed OME-TIFF from ImageJ/FIJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import suite2p\n",
    "from suite2p.run_s2p import run_s2p\n",
    "\n",
    "# set your options for running\n",
    "# overwrites the run_s2p.default_ops\n",
    "ops = {\n",
    "        'fast_disk': [], # used to store temporary binary file, defaults to save_path0 (set as a string NOT a list)\n",
    "        'save_path0': [], # stores results, defaults to first item in data_path\n",
    "        'delete_bin': False, # whether to delete binary file after processing\n",
    "        # main settings\n",
    "        'nplanes' : 1, # each tiff has these many planes in sequence\n",
    "        'nchannels' : 1, # each tiff has these many channels per plane\n",
    "        'functional_chan' : 1, # this channel is used to extract functional ROIs (1-based)\n",
    "        'diameter':4.5, # this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "        'tau':  2.0, # this is the main parameter for deconvolution (GCaMP6f = 0.7; GCaMP6m = 1.25; GCaMP6s = 2.0)\n",
    "        'fs': 6.1,  # sampling rate (total across planes) (128 x 128 = 12.2; 256 x 128 = 6.1)\n",
    "        # output settings\n",
    "        'save_mat': False, # whether to save output as matlab files\n",
    "        'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "        # parallel settings\n",
    "        'num_workers': 0, # 0 to select num_cores, -1 to disable parallelism, N to enforce value\n",
    "        'num_workers_roi': -1, # 0 to select number of planes, -1 to disable parallelism, N to enforce value\n",
    "        # registration settings\n",
    "        'do_registration': True, # whether to register data\n",
    "        'nimg_init': 200, # subsampled frames for finding reference image\n",
    "        'batch_size': 200, # number of frames per batch\n",
    "        'maxregshift': 0.1, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "        'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "        'reg_tif': True, # whether to save registered tiffs\n",
    "        'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "        'nonrigid': False, # wheter to perform non-rigid registration\n",
    "        # cell detection settings\n",
    "        'connected': False, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "        'navg_frames_svd': 5000, # max number of binned frames for the SVD\n",
    "        'nsvd_for_roi': 1000, # max number of SVD components to keep for ROI detection\n",
    "        'max_iterations': 20, # maximum number of iterations to do cell detection\n",
    "        'ratio_neuropil': 6., # ratio between neuropil basis size and cell radius\n",
    "        'ratio_neuropil_to_cell': 3, # minimum ratio between neuropil radius and cell radius\n",
    "        'tile_factor': 1., # use finer (>1) or coarser (<1) tiles for neuropil estimation during cell detection\n",
    "        'threshold_scaling': 1., # adjust the automatically determined threshold by this scalar multiplier\n",
    "        'max_overlap': 0.75, # cells with more overlap than this get removed during triage, before refinement\n",
    "        'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "        'outer_neuropil_radius': np.inf, # maximum neuropil radius\n",
    "        'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "        # deconvolution settings\n",
    "        'baseline': 'maximin', # baselining mode\n",
    "        'win_baseline': 60., # window for maximin\n",
    "        'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "        'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "        'neucoeff': .7,  # neuropil coefficient\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide an h5 path in 'h5py' or a tiff path in 'data_path'\n",
    "# db overwrites any ops (allows for experiment specific settings)\n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "#       'data_path': ['/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/20190502_ChATgCaMP6s_6dpf_partial/test'], # a list of folders with tiffs \n",
    "      'data_path': ['/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/ChAT_gCaMP6s_example2'], # a list of folders with tiffs \n",
    "                                             # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "                                            \n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "      'fast_disk': [], # string which specifies where the binary file will be stored (should be an SSD)\n",
    "    }\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p(ops=ops,db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of db's and loop over them\n",
    "db = []\n",
    "db.append({'data_path': ['C:/Users/carse/github/tiffs']})\n",
    "db.append({'data_path': ['C:/Users/carse/github/tiffs2']})\n",
    "\n",
    "for dbi in db:\n",
    "    opsEnd=run_s2p(ops=ops,db=dbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run on specified tiffs\n",
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data',\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': ['C:/Users/carse/github/tiffs/'], \n",
    "                            # a list of folders with tiffs \n",
    "                            # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "                            \n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "      'fast_disk': 'C:/BIN', # string which specifies where the binary file will be stored (should be an SSD)\n",
    "      'tiff_list': ['file022.tif', 'file023.tif'] # list of tiffs in folder * data_path *!\n",
    "    }\n",
    "\n",
    "\n",
    "# run one experiment\n",
    "opsEnd=run_s2p(ops=ops,db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nFrames(ops):\n",
    "    nbytes = os.path.getsize(ops['reg_file'])\n",
    "    nFrames = int(nbytes/(2* ops['Ly'] *  ops['Lx']))\n",
    "    return nFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops1 = np.load('/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/20190502_ChATgCaMP6s_6dpf_partial/test/suite2p/ops1.npy')\n",
    "ops = np.load('/Users/angueyraaristjm/Documents/LiImaging/TwoPhoton/20190502_ChATgCaMP6s_6dpf_partial/test/suite2p/plane0/ops.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.getsize(ops['reg_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BeautifulSoup to parse tiff ImageDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "metadata = bs(tif.description(0),'xml')\n",
    "Lt = float(metadata.Pixels.get_attribute_list('SizeT')[0])\n",
    "Lx = float(metadata.Pixels.get_attribute_list('SizeX')[0])\n",
    "Ly = float(metadata.Pixels.get_attribute_list('SizeY')[0])\n",
    "nChannels = float(metadata.Pixels.get_attribute_list('SizeC')[0])\n",
    "realX = np.multiply(float(metadata.ImagePhysicalDimensions.get_attribute_list('PhysicalSizeX')[0]),1e6)\n",
    "realXUnit = 'um'\n",
    "realY = np.multiply(float(metadata.ImagePhysicalDimensions.get_attribute_list('PhysicalSizeY')[0]),1e6)\n",
    "realYUnit = 'um'\n",
    "realT = float(metadata.ImagePhysicalDimensions.get_attribute_list('PhysicalSizeT')[0])\n",
    "realXUnit = 's'\n",
    "samplingRate = np.divide(Lt,realT)\n",
    "# print (bs.prettify(metadata))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
